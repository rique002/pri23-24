{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRI Project - Data Processing\n",
    "\n",
    "Write something about the project here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write something about data 1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data 1 csv and drop the unnecessary data\n",
    "jobs_data_1 = pd.read_csv('data/allJobs.csv')\n",
    "jobs_data_1.drop(columns=['Date-Posted'],inplace=True)\n",
    "jobs_data_1.dropna()\n",
    "jobs_data_1.rename(columns = {'Company':'company','Job-Title':'title','Job-Type':'work-type','Salary':'salary','Location':'location','Description':'description'}, inplace = True)\n",
    "jobs_data_1 = jobs_data_1[jobs_data_1.salary.notnull()]\n",
    "jobs_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write something about data 2 hera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data 2 csv and drop the unnecessary data\n",
    "jobs_data_2 = pd.read_csv('data/job_postings.csv')\n",
    "jobs_data_2.drop(columns=['max_salary','min_salary','job_id','expiry','closed_time','applies','currency','compensation_type','original_listed_time','remote_allowed','views','job_posting_url','application_url','application_type','formatted_experience_level','skills_desc','listed_time','posting_domain','sponsored','work_type'],inplace=True)\n",
    "jobs_data_2 = jobs_data_2[jobs_data_2.pay_period.notnull()]\n",
    "jobs_data_2 = jobs_data_2[jobs_data_2.med_salary.notnull()]\n",
    "jobs_data_2.rename(columns = {'med_salary':'salary','formatted_work_type':'work-type'}, inplace = True)\n",
    "jobs_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write something about the salary in jobs_data_1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_and_pay_period(salary_string):\n",
    "    if 'a year' in salary_string:\n",
    "        pay_period = 'YEARLY'\n",
    "        match = re.search(r'\\$([\\d,.]+[kK]?)-?([\\d,.]+[kK]?)?', salary_string)\n",
    "        if match:\n",
    "            low_value = match.group(1).replace(',', '').replace('k', '000').replace('K', '000')\n",
    "            high_value = match.group(2).replace(',', '').replace('k', '000').replace('K', '000') if match.group(2) else low_value\n",
    "            salary = (float(low_value) + float(high_value)) / 2\n",
    "        else:\n",
    "            match = re.search(r'\\$([\\d,.]+[kK]?)', salary_string)\n",
    "            if match:\n",
    "                salary = float(match.group(1).replace(',', '').replace('k', '000').replace('K', '000'))\n",
    "            else:\n",
    "                salary = None\n",
    "    elif 'a month' in salary_string:\n",
    "        pay_period = 'MONTHLY'\n",
    "        match = re.findall(r'\\$([\\d,.]+[kK]?)', salary_string)\n",
    "        if match:\n",
    "            salary_range = [(float(m.replace(',', '').replace('k', '000').replace('K', '000'))) for m in match]\n",
    "            salary = sum(salary_range) / len(salary_range)\n",
    "        else:\n",
    "            salary = None\n",
    "    elif 'an hour' in salary_string:\n",
    "        pay_period = 'HOURLY'\n",
    "        match = re.search(r'\\$([\\d,.]+[kK]?)', salary_string)\n",
    "        if match:\n",
    "            salary = float(match.group(1).replace(',', '').replace('k', '000').replace('K', '000'))\n",
    "        else:\n",
    "            salary = None\n",
    "    else:\n",
    "        pay_period = 'unknown'\n",
    "        salary = None\n",
    "    return salary, pay_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... apply the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the salary collumn into salary and pay period\n",
    "jobs_data_1['salary'], jobs_data_1['pay_period'] = zip(*jobs_data_1['salary'].apply(extract_salary_and_pay_period))\n",
    "jobs_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. add company data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for company data\n",
    "company_data_1 = jobs_data_1['company'].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "company_data_1.columns = ['company_id', 'company']\n",
    "company_data_1['company_id'] = company_data_1['company_id'] + 3700152515\n",
    "\n",
    "jobs_data_1 = pd.merge(jobs_data_1, company_data_1, on='company', how='left')\n",
    "jobs_data_1.drop(columns=['company'],inplace=True)\n",
    "jobs_data_1['work-type'].replace({'Contractor': 'Contract'}, inplace=True)\n",
    "\n",
    "company_data_2 = pd.read_csv('data/companies.csv')\n",
    "company_data_2.drop(columns=['description',\t'company_size',\t'state'\t,'country'\t,'city',\t'zip_code',\t'address',\t'url'],inplace=True)\n",
    "company_data_2.rename(columns = {'name':'company'}, inplace = True)\n",
    "\n",
    "company_data = pd.concat([company_data_1,company_data_2])\n",
    "company_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "jobs_data = pd.concat([jobs_data_1, jobs_data_2], ignore_index=True)\n",
    "jobs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... write something about country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read countries csv and drop the unnecessary data\n",
    "countries_data = pd.read_csv('data/countries.csv')\n",
    "countries_data = countries_data[['name','alpha-2','region','sub-region']]\n",
    "countries_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... extract city and country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city_and_country(location_string, country_list):\n",
    "    splited_location = location_string.split(',')\n",
    "    first_word = splited_location[0]\n",
    "    last_word = splited_location[-1][1:]\n",
    "    country_names = country_list['name'].values\n",
    "    country_alpha = country_list['alpha-2'].values\n",
    "\n",
    "    if first_word in country_names:\n",
    "        return None, first_word\n",
    "    elif first_word in country_alpha:\n",
    "        country = country_list[country_list['alpha-2'] == first_word]['name'].iloc[0]\n",
    "        return None, country\n",
    "    elif last_word in country_names:\n",
    "        return first_word, last_word  \n",
    "    elif last_word in country_alpha:\n",
    "        country = country_list[country_list['alpha-2'] == last_word]['name'].iloc[0]\n",
    "        return first_word, country  \n",
    "    elif len(splited_location) > 0:\n",
    "        return first_word, 'United States of America'\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... aply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create location table\n",
    "jobs_location_data = pd.DataFrame(jobs_data['location'], columns=['location'])\n",
    "jobs_location_data['city'], jobs_location_data['country'] = zip(*jobs_location_data['location'].apply(lambda x: extract_city_and_country(x, countries_data)))\n",
    "jobs_location_data.drop_duplicates(inplace=True)\n",
    "jobs_location_data.reset_index(drop=True, inplace=True)\n",
    "jobs_location_data.insert(0, 'location_id', range(1, 1 + len(jobs_location_data)))\n",
    "\n",
    "jobs_data = pd.merge(jobs_data, jobs_location_data[['location', 'location_id']], on='location', how='left')\n",
    "jobs_data.drop(columns=['location'], inplace=True)\n",
    "\n",
    "jobs_location_data.drop(columns=['location'], inplace=True)\n",
    "jobs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... graphic 8K HDR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jobs_data['pay_period'].value_counts().plot(kind='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
